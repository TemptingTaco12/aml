{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1331ab9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.009031,
     "end_time": "2023-05-22T15:47:54.700245",
     "exception": false,
     "start_time": "2023-05-22T15:47:54.691214",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Example solution for tweet sentiment analysis\n",
    "\n",
    "This is a baseline example to help you with the third challenge. It was originally developed by our Ph.D. student Jonas Wacker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7880be90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:54.721023Z",
     "iopub.status.busy": "2023-05-22T15:47:54.719768Z",
     "iopub.status.idle": "2023-05-22T15:47:57.073746Z",
     "shell.execute_reply": "2023-05-22T15:47:57.072336Z"
    },
    "papermill": {
     "duration": 2.367645,
     "end_time": "2023-05-22T15:47:57.076723",
     "exception": false,
     "start_time": "2023-05-22T15:47:54.709078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# general NLP preprocessing and basic tools\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "# basic machine learning models\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# our evaluation metric for sentiment classification\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "13989271",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:57.097560Z",
     "iopub.status.busy": "2023-05-22T15:47:57.097072Z",
     "iopub.status.idle": "2023-05-22T15:47:57.105300Z",
     "shell.execute_reply": "2023-05-22T15:47:57.103815Z"
    },
    "papermill": {
     "duration": 0.0219,
     "end_time": "2023-05-22T15:47:57.107721",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.085821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23e81981",
   "metadata": {
    "papermill": {
     "duration": 0.008622,
     "end_time": "2023-05-22T15:47:57.125527",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.116905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f8a4d5ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:57.145295Z",
     "iopub.status.busy": "2023-05-22T15:47:57.144882Z",
     "iopub.status.idle": "2023-05-22T15:47:57.305174Z",
     "shell.execute_reply": "2023-05-22T15:47:57.304043Z"
    },
    "papermill": {
     "duration": 0.173509,
     "end_time": "2023-05-22T15:47:57.308072",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.134563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('kaggle/input/eurecom-aml-2023-challenge-3/train.csv')\n",
    "test_df = pd.read_csv('kaggle/input/eurecom-aml-2023-challenge-3/test.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8df8ad88",
   "metadata": {
    "papermill": {
     "duration": 0.008508,
     "end_time": "2023-05-22T15:47:57.325677",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.317169",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Quick data inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "969e9c1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:57.345341Z",
     "iopub.status.busy": "2023-05-22T15:47:57.344921Z",
     "iopub.status.idle": "2023-05-22T15:47:57.352338Z",
     "shell.execute_reply": "2023-05-22T15:47:57.351552Z"
    },
    "papermill": {
     "duration": 0.019999,
     "end_time": "2023-05-22T15:47:57.354648",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.334649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27480"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)+len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "128fd274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:57.375287Z",
     "iopub.status.busy": "2023-05-22T15:47:57.374488Z",
     "iopub.status.idle": "2023-05-22T15:47:57.406437Z",
     "shell.execute_reply": "2023-05-22T15:47:57.405493Z"
    },
    "papermill": {
     "duration": 0.045008,
     "end_time": "2023-05-22T15:47:57.408807",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.363799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28ac06f416</td>\n",
       "      <td>good luck with your auction</td>\n",
       "      <td>good luck with your auction</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92098cf9a7</td>\n",
       "      <td>Hmm..You can`t judge a book by looking at its ...</td>\n",
       "      <td>Hmm..You can`t judge a book by looking at its ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7858ff28f2</td>\n",
       "      <td>Hello, yourself. Enjoy London. Watch out for ...</td>\n",
       "      <td>They`re mental.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b0c9c67f32</td>\n",
       "      <td>We can`t even call you from belgium  sucks</td>\n",
       "      <td>m  suck</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7b36e9e7a5</td>\n",
       "      <td>not so good mood..</td>\n",
       "      <td>not so good mood..</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  28ac06f416                        good luck with your auction   \n",
       "1  92098cf9a7  Hmm..You can`t judge a book by looking at its ...   \n",
       "2  7858ff28f2   Hello, yourself. Enjoy London. Watch out for ...   \n",
       "3  b0c9c67f32         We can`t even call you from belgium  sucks   \n",
       "4  7b36e9e7a5                                 not so good mood..   \n",
       "\n",
       "                                       selected_text sentiment  \n",
       "0                        good luck with your auction  positive  \n",
       "1  Hmm..You can`t judge a book by looking at its ...   neutral  \n",
       "2                                    They`re mental.  negative  \n",
       "3                                            m  suck  negative  \n",
       "4                                 not so good mood..  negative  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2990d54d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:57.429632Z",
     "iopub.status.busy": "2023-05-22T15:47:57.429247Z",
     "iopub.status.idle": "2023-05-22T15:47:57.439949Z",
     "shell.execute_reply": "2023-05-22T15:47:57.438864Z"
    },
    "papermill": {
     "duration": 0.02434,
     "end_time": "2023-05-22T15:47:57.442741",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.418401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102f98e5e2</td>\n",
       "      <td>Happy Mother`s Day hahaha</td>\n",
       "      <td>Happy Mother`s Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>033b399113</td>\n",
       "      <td>Sorry for the triple twitter post, was having ...</td>\n",
       "      <td>Sorry for the triple twitter post, was having ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c125e29be2</td>\n",
       "      <td>thats much better than the flu syndrome!</td>\n",
       "      <td>thats much better</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b91e2b0679</td>\n",
       "      <td>Aww I have a tummy ache</td>\n",
       "      <td>tummy ache</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a46141274</td>\n",
       "      <td>hey chocolate chips is good.  i want a snack ...</td>\n",
       "      <td>good.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       textID                                               text  \\\n",
       "0  102f98e5e2                          Happy Mother`s Day hahaha   \n",
       "1  033b399113  Sorry for the triple twitter post, was having ...   \n",
       "2  c125e29be2           thats much better than the flu syndrome!   \n",
       "3  b91e2b0679                            Aww I have a tummy ache   \n",
       "4  1a46141274   hey chocolate chips is good.  i want a snack ...   \n",
       "\n",
       "                                       selected_text  \n",
       "0                                 Happy Mother`s Day  \n",
       "1  Sorry for the triple twitter post, was having ...  \n",
       "2                                  thats much better  \n",
       "3                                         tummy ache  \n",
       "4                                              good.  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac212b87",
   "metadata": {
    "papermill": {
     "duration": 0.009056,
     "end_time": "2023-05-22T15:47:57.461623",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.452567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "5dc776a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:57.483821Z",
     "iopub.status.busy": "2023-05-22T15:47:57.482781Z",
     "iopub.status.idle": "2023-05-22T15:47:57.504979Z",
     "shell.execute_reply": "2023-05-22T15:47:57.503784Z"
    },
    "papermill": {
     "duration": 0.036337,
     "end_time": "2023-05-22T15:47:57.507649",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.471312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we create a validation dataset from the training data\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1bbea491",
   "metadata": {
    "papermill": {
     "duration": 0.00891,
     "end_time": "2023-05-22T15:47:57.525942",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.517032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We start off by converting the labels to numbers. This is a requirement for the submission and numerical inputs are generally more compatible with machine learning libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "90dddd24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:57.546295Z",
     "iopub.status.busy": "2023-05-22T15:47:57.545882Z",
     "iopub.status.idle": "2023-05-22T15:47:57.552136Z",
     "shell.execute_reply": "2023-05-22T15:47:57.550347Z"
    },
    "papermill": {
     "duration": 0.019636,
     "end_time": "2023-05-22T15:47:57.554763",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.535127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_conversion = {\n",
    "    'neutral': 0,\n",
    "    'positive': 1,\n",
    "    'negative': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "67e90ada",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:57.576102Z",
     "iopub.status.busy": "2023-05-22T15:47:57.575668Z",
     "iopub.status.idle": "2023-05-22T15:47:57.589589Z",
     "shell.execute_reply": "2023-05-22T15:47:57.588341Z"
    },
    "papermill": {
     "duration": 0.028105,
     "end_time": "2023-05-22T15:47:57.592571",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.564466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['target'] = train_df['sentiment'].map(target_conversion)\n",
    "val_df['target'] = val_df['sentiment'].map(target_conversion)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99d2a5a4",
   "metadata": {
    "papermill": {
     "duration": 0.00955,
     "end_time": "2023-05-22T15:47:57.611893",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.602343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we need to find a numerical representation for our input data. Extracting features from text is one of the major building blocks of any Natural Language Processing (NLP) pipeline.\n",
    "\n",
    "There have been huge developments in the field during the last decade. A very traditional approach is to extract Bag-of-Words features. See here for an explanation:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction\n",
    "\n",
    "We will stick to this technique for the purpose of this example notebook. However, be aware that much more powerful feature extraction techniques exist. The most recent ones use neural network based language models. See e.g.:\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2019/06/understanding-transformers-nlp-state-of-the-art-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "86987571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ab33068/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ab33068/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')  # Download the tokenizer resource\n",
    "nltk.download('stopwords') # Download the stopwords resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "ce9a0dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom tokenizer function\n",
    "def custom_tokenizer(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    #tokens = [token for token in tokens if token.lower() not in stop_words] # Apply lowercasing to each token not in stop words\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(token) for token in tokens]\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "# Define pretrained tokenizer function\n",
    "def auto_tokenizer(text):\n",
    "    bert_uncased_tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', do_basic_tokenize=False, use_fast=True)\n",
    "    # bert_cased_tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "    # roberta_base_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "    # roberta_large_tokenizer = AutoTokenizer.from_pretrained('roberta-large')\n",
    "    # gpt_tokenizer = AutoTokenizer.from_pretrained('gpt2', add_special_tokens=True, use_fast=True)\n",
    "\n",
    "    tokens = bert_uncased_tokenizer.tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9b0eaf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation of hyperparameters\n",
    "\n",
    "# pipeline = Pipeline([\n",
    "#     ('vectorizer', CountVectorizer(tokenizer=custom_tokenizer)),\n",
    "#     ('classifier', MultinomialNB())\n",
    "# ])\n",
    "\n",
    "# Defines the parameter grid to search over\n",
    "# param_grid = {\n",
    "#     'vectorizer__ngram_range': [(1, 1), \n",
    "#                                 (1, 2), \n",
    "#                                 (1, 3),\n",
    "#                                 (1, 4),\n",
    "#                                 (2, 2),\n",
    "#                                 (2, 3),\n",
    "#                                 (2, 4),\n",
    "#                                 (3, 3),\n",
    "#                                 (3, 4),\n",
    "#                                 (4, 4)]\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(pipeline, param_grid, scoring='f1_macro', cv=10)\n",
    "\n",
    "# grid_search.fit(train_df['text'], train_df['target'])\n",
    "\n",
    "# print(\"Best ngram_range:\", grid_search.best_params_['vectorizer__ngram_range'])\n",
    "# print(\"Best F1 score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ecaf9630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:57.633070Z",
     "iopub.status.busy": "2023-05-22T15:47:57.632620Z",
     "iopub.status.idle": "2023-05-22T15:47:57.638947Z",
     "shell.execute_reply": "2023-05-22T15:47:57.637665Z"
    },
    "papermill": {
     "duration": 0.019726,
     "end_time": "2023-05-22T15:47:57.641609",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.621883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Specifiies the n-gram range we want to extract\n",
    "ngram_range = (1, 3)\n",
    "\n",
    "count_vect = CountVectorizer(\n",
    "    tokenizer=auto_tokenizer, \n",
    "    #tokenizer=custom_tokenizer, \n",
    "    #stop_words=set(stopwords.words('english'))\n",
    "    #ngram_range=ngram_range\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6b6fae5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:57.665172Z",
     "iopub.status.busy": "2023-05-22T15:47:57.663976Z",
     "iopub.status.idle": "2023-05-22T15:47:58.136571Z",
     "shell.execute_reply": "2023-05-22T15:47:58.135314Z"
    },
    "papermill": {
     "duration": 0.487059,
     "end_time": "2023-05-22T15:47:58.139407",
     "exception": false,
     "start_time": "2023-05-22T15:47:57.652348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# here we are obtaining the vocabulary from the training data minus validation data\n",
    "# you may want to change this to the full training data for the final submission\n",
    "X_train_counts = count_vect.fit_transform(list(train_df['text'].values))\n",
    "X_val_counts = count_vect.transform(list(val_df['text'].values))\n",
    "X_test_counts = count_vect.transform(list(test_df['text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "601bef13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:58.160502Z",
     "iopub.status.busy": "2023-05-22T15:47:58.159305Z",
     "iopub.status.idle": "2023-05-22T15:47:58.165652Z",
     "shell.execute_reply": "2023-05-22T15:47:58.164582Z"
    },
    "papermill": {
     "duration": 0.019339,
     "end_time": "2023-05-22T15:47:58.167921",
     "exception": false,
     "start_time": "2023-05-22T15:47:58.148582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train feature shape: (22258, 13578)\n",
      "Validation feature shape: (2474, 13578)\n",
      "Test feature shape: (2748, 13578)\n"
     ]
    }
   ],
   "source": [
    "print('Train feature shape:', X_train_counts.shape)\n",
    "print('Validation feature shape:', X_val_counts.shape)\n",
    "print('Test feature shape:', X_test_counts.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fa6fde5",
   "metadata": {
    "papermill": {
     "duration": 0.009659,
     "end_time": "2023-05-22T15:47:58.187642",
     "exception": false,
     "start_time": "2023-05-22T15:47:58.177983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The Bag-of-Words representation assigns a unique ID to each word that appears in the training data. 23239 unique words have been extracted. Each input data point (tweet) is then represented by a vector of the size of the vocabulary. Each of its elements are the counts of the respective word appearing in the tweet.\n",
    "\n",
    "Therefore, the features have a huge dimension! Storing the feature matrix directly would require (n_datapoints x vocabulary size) * 32 bits  ≈\n",
    "  2 GB CPU/GPU RAM! Imagine we were not analyzing tweets (limited vocabulary) but Wikipedia! Or imagine we had a larger corpus of documents. Then we could not store the features!\n",
    "\n",
    "Instead, the Bag-of-Words features are usually stored using a sparse representation. Imagine this like a dictionary of ID-count tuples assigned to each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1e790898",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:58.208782Z",
     "iopub.status.busy": "2023-05-22T15:47:58.208327Z",
     "iopub.status.idle": "2023-05-22T15:47:58.215726Z",
     "shell.execute_reply": "2023-05-22T15:47:58.214213Z"
    },
    "papermill": {
     "duration": 0.020285,
     "end_time": "2023-05-22T15:47:58.217887",
     "exception": false,
     "start_time": "2023-05-22T15:47:58.197602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22258x13578 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 359141 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we quickly analyze the matrix of word counts:\n",
    "# Only 255125 of the 22258x23162 values => 0.049487% are non-zero.\n",
    "# The sparse encoding only needs to store these.\n",
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "e1c86674",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:58.241105Z",
     "iopub.status.busy": "2023-05-22T15:47:58.240325Z",
     "iopub.status.idle": "2023-05-22T15:47:58.248887Z",
     "shell.execute_reply": "2023-05-22T15:47:58.247445Z"
    },
    "papermill": {
     "duration": 0.024178,
     "end_time": "2023-05-22T15:47:58.251391",
     "exception": false,
     "start_time": "2023-05-22T15:47:58.227213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [3, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yet, we can ask to convert a part of the matrix into the traditional dense format.\n",
    "# It's quite challenging to find any non-zeros here!\n",
    "X_train_counts[:10,:10].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "bcfed126",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:58.276171Z",
     "iopub.status.busy": "2023-05-22T15:47:58.275386Z",
     "iopub.status.idle": "2023-05-22T15:47:58.281975Z",
     "shell.execute_reply": "2023-05-22T15:47:58.280936Z"
    },
    "papermill": {
     "duration": 0.022665,
     "end_time": "2023-05-22T15:47:58.284408",
     "exception": false,
     "start_time": "2023-05-22T15:47:58.261743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11592"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The other way around is easier. We can ask to find the ID (index) of a specific word.\n",
    "count_vect.vocabulary_.get('sleep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "35054083",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:58.305616Z",
     "iopub.status.busy": "2023-05-22T15:47:58.305083Z",
     "iopub.status.idle": "2023-05-22T15:47:58.312632Z",
     "shell.execute_reply": "2023-05-22T15:47:58.311448Z"
    },
    "papermill": {
     "duration": 0.020809,
     "end_time": "2023-05-22T15:47:58.314800",
     "exception": false,
     "start_time": "2023-05-22T15:47:58.293991",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet:\n",
      " had a horrible sleep + in a rather bad mood\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "column index (18618) out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ab33068/Documents/work/aml/challenge3/eurecom-aml-2023-challenge-3-baseline.ipynb Cell 26\u001b[0m in \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ab33068/Documents/work/aml/challenge3/eurecom-aml-2023-challenge-3-baseline.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# So the first tweet should have a one at this position:\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ab33068/Documents/work/aml/challenge3/eurecom-aml-2023-challenge-3-baseline.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTweet:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, train_df\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ab33068/Documents/work/aml/challenge3/eurecom-aml-2023-challenge-3-baseline.ipynb#X33sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mNumber of times the word \u001b[39m\u001b[39m\"\u001b[39m\u001b[39msleep\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m appeared:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, X_train_counts[\u001b[39m0\u001b[39;49m, \u001b[39m18618\u001b[39;49m])\n",
      "File \u001b[0;32m~/anaconda3/envs/malis/lib/python3.8/site-packages/scipy/sparse/_index.py:47\u001b[0m, in \u001b[0;36mIndexMixin.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m---> 47\u001b[0m     row, col \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_indices(key)\n\u001b[1;32m     49\u001b[0m     \u001b[39m# Dispatch to specialized methods.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(row, INT_TYPES):\n",
      "File \u001b[0;32m~/anaconda3/envs/malis/lib/python3.8/site-packages/scipy/sparse/_index.py:164\u001b[0m, in \u001b[0;36mIndexMixin._validate_indices\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    162\u001b[0m col \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(col)\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m col \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mN \u001b[39mor\u001b[39;00m col \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m N:\n\u001b[0;32m--> 164\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mcolumn index (\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m) out of range\u001b[39m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m col)\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m col \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    166\u001b[0m     col \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m N\n",
      "\u001b[0;31mIndexError\u001b[0m: column index (18618) out of range"
     ]
    }
   ],
   "source": [
    "# So the first tweet should have a one at this position:\n",
    "# print('Tweet:\\n', train_df.iloc[0]['text'])\n",
    "# print('Number of times the word \"sleep\" appeared:\\n', X_train_counts[0, 18618])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "189ac5bb",
   "metadata": {
    "papermill": {
     "duration": 0.009336,
     "end_time": "2023-05-22T15:47:58.334232",
     "exception": false,
     "start_time": "2023-05-22T15:47:58.324896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training a simple classifier\n",
    "\n",
    "We are training a naive Bayes classifier on the Bag-of-Words features of the training data:\n",
    "\n",
    "https://nlp.stanford.edu/IR-book/html/htmledition/naive-bayes-text-classification-1.html\n",
    "\n",
    "It is already built into the sklearn library:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "\n",
    "Keep in mind that not only storing the features is challenging but also processing them. A simple SVM may be quite slow on such high-dimensional features. Naive Bayes works well with Bag-of-Words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8e86e7b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:58.356522Z",
     "iopub.status.busy": "2023-05-22T15:47:58.355741Z",
     "iopub.status.idle": "2023-05-22T15:47:58.377310Z",
     "shell.execute_reply": "2023-05-22T15:47:58.375769Z"
    },
    "papermill": {
     "duration": 0.03574,
     "end_time": "2023-05-22T15:47:58.379558",
     "exception": false,
     "start_time": "2023-05-22T15:47:58.343818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.81 ms, sys: 0 ns, total: 4.81 ms\n",
      "Wall time: 4.48 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = MultinomialNB().fit(X_train_counts, train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "8feaac84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:58.401904Z",
     "iopub.status.busy": "2023-05-22T15:47:58.401127Z",
     "iopub.status.idle": "2023-05-22T15:47:58.408299Z",
     "shell.execute_reply": "2023-05-22T15:47:58.407517Z"
    },
    "papermill": {
     "duration": 0.020647,
     "end_time": "2023-05-22T15:47:58.410499",
     "exception": false,
     "start_time": "2023-05-22T15:47:58.389852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_predictions_nb = clf.predict(X_val_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4e02a8ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:58.433351Z",
     "iopub.status.busy": "2023-05-22T15:47:58.432959Z",
     "iopub.status.idle": "2023-05-22T15:47:58.439950Z",
     "shell.execute_reply": "2023-05-22T15:47:58.438222Z"
    },
    "papermill": {
     "duration": 0.020954,
     "end_time": "2023-05-22T15:47:58.442135",
     "exception": false,
     "start_time": "2023-05-22T15:47:58.421181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of our multinomial Naive Bayes classifier is: 64.03%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (val_predictions_nb == val_df['target'].values).mean()\n",
    "print('The accuracy of our multinomial Naive Bayes classifier is: {:.2f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "16937191",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:58.464779Z",
     "iopub.status.busy": "2023-05-22T15:47:58.464309Z",
     "iopub.status.idle": "2023-05-22T15:47:58.475264Z",
     "shell.execute_reply": "2023-05-22T15:47:58.473609Z"
    },
    "papermill": {
     "duration": 0.025117,
     "end_time": "2023-05-22T15:47:58.477728",
     "exception": false,
     "start_time": "2023-05-22T15:47:58.452611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fbeta score is: 0.643050603503292\n"
     ]
    }
   ],
   "source": [
    "fbeta = fbeta_score(val_df['target'].values, val_predictions_nb, average='macro', beta=1.0)\n",
    "print('The fbeta score is:', fbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "96a493e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:58.502341Z",
     "iopub.status.busy": "2023-05-22T15:47:58.500783Z",
     "iopub.status.idle": "2023-05-22T15:47:58.980825Z",
     "shell.execute_reply": "2023-05-22T15:47:58.979671Z"
    },
    "papermill": {
     "duration": 0.496208,
     "end_time": "2023-05-22T15:47:58.984220",
     "exception": false,
     "start_time": "2023-05-22T15:47:58.488012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating a submission\n",
    "\n",
    "X_train_counts = count_vect.fit_transform(list(train_df['text'].values) + list(val_df['text'].values))\n",
    "X_test_counts = count_vect.transform(list(test_df['text'].values))\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_counts, np.hstack([train_df['target'].values, val_df['target'].values]))\n",
    "test_predictions_nb = clf.predict(X_test_counts)\n",
    "\n",
    "submission_df = pd.DataFrame()\n",
    "submission_df['textID'] = test_df['textID']\n",
    "submission_df['sentiment'] = test_predictions_nb\n",
    "submission_df.to_csv('TA_baseline_NB.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df01cbfe",
   "metadata": {
    "papermill": {
     "duration": 0.011562,
     "end_time": "2023-05-22T15:47:59.005787",
     "exception": false,
     "start_time": "2023-05-22T15:47:58.994225",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## How good is this score?\n",
    "\n",
    "Early approaches in NLP used rule-based classifiers for sentiment analysis. A popular baseline is VADER which was published in 2014:\n",
    "\n",
    "https://www.aaai.org/ocs/index.php/ICWSM/ICWSM14/paper/viewPaper/8109\n",
    "\n",
    "VADER does not use any machine learning but is purely handcrafted by humans. It uses text preprocessing and lexica to determine the sentiment of a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "8c31cc37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:59.027479Z",
     "iopub.status.busy": "2023-05-22T15:47:59.027073Z",
     "iopub.status.idle": "2023-05-22T15:47:59.215950Z",
     "shell.execute_reply": "2023-05-22T15:47:59.214614Z"
    },
    "papermill": {
     "duration": 0.202593,
     "end_time": "2023-05-22T15:47:59.218487",
     "exception": false,
     "start_time": "2023-05-22T15:47:59.015894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/ab33068/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e5f0b93d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:59.241740Z",
     "iopub.status.busy": "2023-05-22T15:47:59.241347Z",
     "iopub.status.idle": "2023-05-22T15:47:59.260676Z",
     "shell.execute_reply": "2023-05-22T15:47:59.259476Z"
    },
    "papermill": {
     "duration": 0.035011,
     "end_time": "2023-05-22T15:47:59.263978",
     "exception": false,
     "start_time": "2023-05-22T15:47:59.228967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9d77c810",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:59.287530Z",
     "iopub.status.busy": "2023-05-22T15:47:59.287084Z",
     "iopub.status.idle": "2023-05-22T15:47:59.294787Z",
     "shell.execute_reply": "2023-05-22T15:47:59.293837Z"
    },
    "papermill": {
     "duration": 0.022,
     "end_time": "2023-05-22T15:47:59.297174",
     "exception": false,
     "start_time": "2023-05-22T15:47:59.275174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " couple days?! Sheeeeit. Wish I were there. Have something at Cafe Claude for me.\n",
      "{'neg': 0.0, 'neu': 0.8, 'pos': 0.2, 'compound': 0.4574}\n",
      "She didn`t make the challenge\n",
      "{'neg': 0.0, 'neu': 0.755, 'pos': 0.245, 'compound': 0.0772}\n",
      "@_laertesgirl Ohh of course. She did stop once though, end of Dream. John Woodvine & Zoe Thorne, only ones not signed my programme\n",
      "{'neg': 0.091, 'neu': 0.826, 'pos': 0.083, 'compound': -0.0516}\n",
      "happy mother`s day mom. love you always\n",
      "{'neg': 0.0, 'neu': 0.388, 'pos': 0.612, 'compound': 0.836}\n",
      "I`m at my saddest right now. I lost my mobile phone earphones. Waz feels a little incomplete and I feel the same\n",
      "{'neg': 0.27, 'neu': 0.73, 'pos': 0.0, 'compound': -0.743}\n"
     ]
    }
   ],
   "source": [
    "# We show a few prediction examples:\n",
    "for doc in val_df['text'].iloc[:5].values:\n",
    "    print(doc)\n",
    "    print(sid.polarity_scores(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "478bc6b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:59.320905Z",
     "iopub.status.busy": "2023-05-22T15:47:59.320501Z",
     "iopub.status.idle": "2023-05-22T15:47:59.326814Z",
     "shell.execute_reply": "2023-05-22T15:47:59.325868Z"
    },
    "papermill": {
     "duration": 0.02075,
     "end_time": "2023-05-22T15:47:59.329099",
     "exception": false,
     "start_time": "2023-05-22T15:47:59.308349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def vader_predict(x):\n",
    "    prediction = sid.polarity_scores(x)\n",
    "    prediction_list = [\n",
    "        (1, prediction['pos']),\n",
    "        (-1, prediction['neg']),\n",
    "        (0, prediction['neu'])\n",
    "    ]\n",
    "    label = sorted(prediction_list, key=lambda x: x[1], reverse=True)[0][0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9a58f284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:59.352271Z",
     "iopub.status.busy": "2023-05-22T15:47:59.351933Z",
     "iopub.status.idle": "2023-05-22T15:47:59.872561Z",
     "shell.execute_reply": "2023-05-22T15:47:59.871050Z"
    },
    "papermill": {
     "duration": 0.536793,
     "end_time": "2023-05-22T15:47:59.876745",
     "exception": false,
     "start_time": "2023-05-22T15:47:59.339952",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions_vader = val_df['text'].apply(vader_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "45d3c297",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:59.909990Z",
     "iopub.status.busy": "2023-05-22T15:47:59.909533Z",
     "iopub.status.idle": "2023-05-22T15:47:59.916203Z",
     "shell.execute_reply": "2023-05-22T15:47:59.915414Z"
    },
    "papermill": {
     "duration": 0.026732,
     "end_time": "2023-05-22T15:47:59.919575",
     "exception": false,
     "start_time": "2023-05-22T15:47:59.892843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of VADER is: 48.67%\n"
     ]
    }
   ],
   "source": [
    "accuracy = (predictions_vader == val_df['target'].values).mean()\n",
    "print('The accuracy of VADER is: {:.2f}%'.format(accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "940e25c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:47:59.952441Z",
     "iopub.status.busy": "2023-05-22T15:47:59.952016Z",
     "iopub.status.idle": "2023-05-22T15:47:59.969255Z",
     "shell.execute_reply": "2023-05-22T15:47:59.963145Z"
    },
    "papermill": {
     "duration": 0.037133,
     "end_time": "2023-05-22T15:47:59.972045",
     "exception": false,
     "start_time": "2023-05-22T15:47:59.934912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fbeta score is: 0.37428265742622274\n"
     ]
    }
   ],
   "source": [
    "fbeta = fbeta_score(val_df['target'].values, predictions_vader, average='macro', beta=1.0)\n",
    "print('The fbeta score is:', fbeta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e1a25d7",
   "metadata": {
    "papermill": {
     "duration": 0.012881,
     "end_time": "2023-05-22T15:47:59.996514",
     "exception": false,
     "start_time": "2023-05-22T15:47:59.983633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "VADER performs worse! That is a good sign that our classifier learned useful generalizations from the training data (better than standard handcrafted rules)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4e64845",
   "metadata": {
    "papermill": {
     "duration": 0.011512,
     "end_time": "2023-05-22T15:48:00.019748",
     "exception": false,
     "start_time": "2023-05-22T15:48:00.008236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Where to go from here?\n",
    "\n",
    "We can improve our Machine Learning pipeline on multiple aspects:\n",
    "\n",
    "### Data analysis:\n",
    "How is the data distributed? Can we analyze our data to find patterns associated with the classes? Which kinds of words are useful, which aren't?\n",
    "\n",
    "### Feature extraction:\n",
    "Can we make our Bag-of-Words representation more compact or richer? There are many things you could try to implement. Here are some buzzwords: tokenization, stop words removal, lemmatization, n-gram extraction, ...\n",
    "A useful Python library to address these issues is: NLTK (https://www.nltk.org/)\n",
    "The sklearn CountVectorizer we used can be combined with NLTK preprocessing: https://scikit-learn.org/stable/modules/feature_extraction.html#customizing-the-vectorizer-classes\n",
    "Is there also a dense (as opposed to sparse) representation of documents (tweets in our case)? Buzzwords: word2vec, gloVe\n",
    "The state-of-the-art: ... are neural network language models, so-called Transformers. There are pretrained models available. If you feel comfortable with neural networks, fine-tuning and GPUs, have a look here: https://huggingface.co/transformers/\n",
    "\n",
    "In general, we also recommend spaCy as a convenient Python library that covers most of the above features at once and may be a great resource to start with: https://spacy.io/\n",
    "\n",
    "### Model selection:\n",
    "The model of choice highly depends on the previously extracted features. Depending on whether you obtain a sparse or dense feature representation, you have to choose an appropriate model!\n",
    "\n",
    "### Model evaluation:\n",
    "Make sure to select potential model hyperparameters using cross-validation or similar. Our evaluation metric of choice is the F1-score:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html#sklearn.metrics.fbeta_score\n",
    "\n",
    "We choose beta=1 and average=macro\n",
    "\n",
    "### Extension idea 1:\n",
    "Apart from classifying the sentiment of tweets, we can also try to determine which words are the reason for the classifier to determine the classification. Ground-truth labels for these words are contained in our training data. The evaluation will not take place on the Kaggle platform. You need to do it yourself. Use the Jaccard coefficient to evaluate the overlap between the selected words and the ground truth:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#jaccard-similarity-coefficient-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372d0824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-22T15:48:00.047669Z",
     "iopub.status.busy": "2023-05-22T15:48:00.047016Z",
     "iopub.status.idle": "2023-05-22T15:48:00.061061Z",
     "shell.execute_reply": "2023-05-22T15:48:00.060101Z"
    },
    "papermill": {
     "duration": 0.030136,
     "end_time": "2023-05-22T15:48:00.064047",
     "exception": false,
     "start_time": "2023-05-22T15:48:00.033911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>had a horrible sleep + in a rather bad mood</td>\n",
       "      <td>in a rather bad mood</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11840</th>\n",
       "      <td>No but this is our poor week</td>\n",
       "      <td>No but this is our poor week</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16482</th>\n",
       "      <td>_Blogs Congratulations lovely Japanese Childre...</td>\n",
       "      <td>Congratulations lo</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10802</th>\n",
       "      <td>?Happy Birthday to u? Happy Birthday to u? Ha...</td>\n",
       "      <td>?Happy</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13679</th>\n",
       "      <td>i can`t go tonight   *Cait*</td>\n",
       "      <td>i can`t go tonight   *Cait*</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "772          had a horrible sleep + in a rather bad mood   \n",
       "11840                       No but this is our poor week   \n",
       "16482  _Blogs Congratulations lovely Japanese Childre...   \n",
       "10802   ?Happy Birthday to u? Happy Birthday to u? Ha...   \n",
       "13679                        i can`t go tonight   *Cait*   \n",
       "\n",
       "                      selected_text sentiment  \n",
       "772            in a rather bad mood  negative  \n",
       "11840  No but this is our poor week  negative  \n",
       "16482            Congratulations lo  positive  \n",
       "10802                        ?Happy  positive  \n",
       "13679   i can`t go tonight   *Cait*   neutral  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selected_text shows the words selected from text to lead to the classification stored in sentiment\n",
    "train_df[['text', 'selected_text', 'sentiment']].iloc[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77a2aa08",
   "metadata": {
    "papermill": {
     "duration": 0.01657,
     "end_time": "2023-05-22T15:48:00.097195",
     "exception": false,
     "start_time": "2023-05-22T15:48:00.080625",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Extension idea 2:\n",
    "\n",
    "You may want to give it a try to Kaggle's brand new feature called models!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.636291,
   "end_time": "2023-05-22T15:48:01.235515",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-22T15:47:43.599224",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
